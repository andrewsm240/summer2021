## Tasks Completed

- Student Connects meeting
- Able to get `nvprof` working within a Docker container
- Put together my introductory presentation
- Tied together the NX and my desktop using the link-local ipv4 profile

## Notes

- Exploring `nvprof` and how it can be used to produce output logs of Nvidia stack traces and memory copies
  - Here is an example of all the different metrics that it is able to capture: https://gist.github.com/mrprajesh/352cbe661ee27a6b4627ae72d89479e6
  - I can run it like this: `/usr/local/cuda/bin/nvprof --print-gpu-summary --profile-all-processes -o nvprof_%p_out --log-file nvprof_%p_log` and it will attach to the test Docker command that runs the object detector: `python3 /app/app.py -stream bottom_image -object person -interval 1`
  - I have only tested running this command within the Docker container - it may be able to work outside the container too. QUESTION: Is the profiling setup going to reside entirely outside the container or is it ok to load in this command in the background of the app's container?

